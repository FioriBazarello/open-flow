import keyboard
import speech_recognition as sr
import pyperclip
import pyautogui
import threading
import pystray
from PIL import Image
import os

def transcrever_audio():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ™ï¸ Ouvindo...")
        audio = recognizer.listen(source)
    try:
        texto = recognizer.recognize_google(audio, language='pt-BR')
        print("ğŸ“ TranscriÃ§Ã£o:", texto)
        return texto
    except sr.UnknownValueError:
        print("ğŸ˜• NÃ£o entendi o que foi dito.")
        return ""
    except sr.RequestError:
        print("ğŸš« Erro na conexÃ£o com o serviÃ§o.")
        return ""

def iniciar_transcricao():
    texto = transcrever_audio()
    if texto:
        pyperclip.copy(texto)
        pyautogui.hotkey('ctrl', 'v')

# Rodar em thread pra nÃ£o travar o hotkey
def ativar_transcricao():
    threading.Thread(target=iniciar_transcricao).start()

def criar_icone():
    # Criar um Ã­cone simples (um quadrado branco)
    image = Image.new('RGB', (64, 64), 'white')
    
    def on_exit(icon, item):
        icon.stop()
        os._exit(0)
    
    menu = pystray.Menu(
        pystray.MenuItem('Sair', on_exit)
    )
    
    icon = pystray.Icon("open-flow", image, "Open Flow", menu)
    return icon

def main():
    keyboard.add_hotkey('ctrl+alt', ativar_transcricao)
    print("âœ… Segure Ctrl+Alt, fale, e solte...")
    print("ğŸ“Œ O programa estÃ¡ rodando em background. Clique com o botÃ£o direito no Ã­cone para sair.")
    
    icon = criar_icone()
    icon.run()

if __name__ == "__main__":
    main()
